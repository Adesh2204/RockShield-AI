version: '3.8'

services:
  # ML Backend Service (Unified ML Service)
  ml-backend:
    build: 
      context: .
      dockerfile: Dockerfile
    ports:
      - "5001:5001"
    environment:
      - FLASK_ENV=production
      - PORT=5001
      - LOG_TO_FILE=false
      - CORS_ORIGINS=http://localhost:5173,http://localhost:5174,https://your-production-domain.com
    volumes:
      - ./ml-service/logs:/app/ml-service/logs
      - ./models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - rockshield-network

  # Frontend Service (for production)
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    ports:
      - "5173:5173"
    depends_on:
      - ml-backend
    environment:
      - VITE_API_URL=http://ml-backend:5001
    restart: unless-stopped
    networks:
      - rockshield-network

  # Nginx Reverse Proxy (optional)
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/ssl/certs:ro
    depends_on:
      - frontend
      - ml-backend
    restart: unless-stopped
    networks:
      - rockshield-network

volumes:
  ml_models:
  app_logs:

networks:
  rockshield-network:
    driver: bridge
